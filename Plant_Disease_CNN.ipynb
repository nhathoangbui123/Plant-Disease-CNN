{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhathoangbui123/Plant-Disease-CNN/blob/main/Plant_Disease_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkWYmWiXvF_6"
      },
      "source": [
        "# Plant Disease Classification using CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ar0QcxR9vF_7"
      },
      "outputs": [],
      "source": [
        "# install library\n",
        "!pip install -q tensorflow\n",
        "!pip install -q split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecj-9WSGvF_8",
        "outputId": "d73551f0-170f-43be-bd8c-a06274c74473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n",
            "unzip:  cannot find or open new-plant-diseases-dataset.zip, new-plant-diseases-dataset.zip.zip or new-plant-diseases-dataset.zip.ZIP.\n",
            "Unzip done.\n"
          ]
        }
      ],
      "source": [
        "# download dataset from Kaggle\n",
        "from google.colab import files\n",
        "# print(\"Upload kaggle.json:\")\n",
        "# files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset\n",
        "!unzip -q new-plant-diseases-dataset.zip -d new_plant_disease\n",
        "print(\"Unzip done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "kejASLkwvF_9",
        "outputId": "c3a98501-9dd1-4d5a-9801-1e5032bb70ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'new_plant_disease/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-4200557535.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mval_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m train_data = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'new_plant_disease/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'"
          ]
        }
      ],
      "source": [
        "# prepare data\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "base_dir = \"new_plant_disease/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"valid\")\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atP0NYifvF_9"
      },
      "outputs": [],
      "source": [
        "# build CNN model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(train_data.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=15,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy and Loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eulIQZvCi4bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "val_preds = model.predict(val_data)\n",
        "y_pred = np.argmax(val_preds, axis=1)\n",
        "y_true = val_data.classes\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=list(val_data.class_indices.keys())))"
      ],
      "metadata": {
        "id": "DakC_CNmi5q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WnhLIdjvF_-"
      },
      "outputs": [],
      "source": [
        "# Upload new image for detect\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    class_names = list(train_data.class_indices.keys())\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Detect: {class_names[predicted_class]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Upload new image\n",
        "from google.colab import files\n",
        "print(\"Please upload new image for detect:\")\n",
        "uploaded = files.upload()\n",
        "for img_path in uploaded.keys():\n",
        "    predict_image(img_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}